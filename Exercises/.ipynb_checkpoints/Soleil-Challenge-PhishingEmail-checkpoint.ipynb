{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ad913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn \n",
    "\n",
    "\n",
    "\n",
    "print(\"scikit-learn version:\", sklearn.__version__)     # 1.1.3\n",
    "print(\"pandas version:\", pd.__version__)            # 1.5.1\n",
    "print(\"seaborn version:\", seaborn.__version__)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Phishing_Email.csv\", index_col=0)\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d4317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'Email Text': 'EmailText','Email Type':'EmailType'}) # changing columns name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497e441",
   "metadata": {},
   "source": [
    "# Checking if there is a missing values in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c56f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.isna().any(axis=1)]\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b229240c",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Target variable\n",
    "Given that machine learning algorithms work with only numbers and therefore produce only numbers as output, the first thing that needs to be done is ascertaining that the target variable is numeric. A new column named `EmailTypeID` is made, that contains a number for ech of the different `EmailType`, and that becomes the target variable for our model. The thing it needs to predict. In order to fill the new column `EmailTypeID` a LabelEncoder is used, which produces a unique number for every unique text it finds in the column `EmailType`. Since there are merely two unique values, the numbers it will give are `0`and `1`. `0` is phishing and `1` is safe.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "df[\"EmailTypeID\"]=encoder.fit_transform(df[\"EmailType\"])\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8970d0e9",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e61a8",
   "metadata": {},
   "source": [
    "Installing NLTK library for tokenization and ignoring English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bccc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --user nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6796d201",
   "metadata": {},
   "source": [
    "Importing packages for tokenization and function to perform natural language pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "#Getting list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    " \n",
    "# converts the words in word_tokens to lower case and then checks whether\n",
    "#they are present in stop_words or not, return tokens without stopwords\n",
    "def remove_stopWords(text):\n",
    "    word_tokens = word_tokenize(stemmer.stem(text))\n",
    "    return [w for w in word_tokens if not w in stop_words]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b45a8",
   "metadata": {},
   "source": [
    "Fill NaN values with empty string to avoid type errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EmailText']=df['EmailText'].fillna('').apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bab638b",
   "metadata": {},
   "source": [
    "Duplicate the EmailText column and perform tokenization to the new one without changing the original Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9110a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TokenizedEmail']= df['EmailText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fdaee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TokenizedEmail'].apply(lambda x: set(remove_stopWords(str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42050f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6319277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd69a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tokenized_Email']= remove_stopWords(str(df['EmailText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = [w for w in tokens if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c7bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41223d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords.words('On 24 Jul 2002, Karl Anderson wrote'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0b3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
